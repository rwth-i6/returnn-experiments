#!rnn.py


import numpy as np

backend = "torch"
batch_size = 2880000
batching = "random"
cache_size = "0"
cleanup_old_models = True
dev = {
    "class": "MetaDataset",
    "datasets": {
        "features": {
            "class": "HDFDataset",
            "use_cache_manager": True,
            "files": [
                "/u/jxu/setups/tedlium2/2024-09-10--construct-better-neural-blocks/work/i6_core/returnn/hdf/BlissToPcmHDFJob.AltkEvXwM3dF/output/audio.hdf"
            ],
        },
        "targets": {
            "class": "HDFDataset",
            "use_cache_manager": True,
            "files": [
                "/u/jxu/setups/tedlium2/2024-09-10--construct-better-neural-blocks/work/i6_experiments/users/berger/recipe/returnn/hdf/BlissCorpusToTargetHdfJob.qGsTLu0lnU5n/output/targets.hdf"
            ],
            "partition_epoch": 1,
            "seq_ordering": "sorted",
        },
    },
    "data_map": {"data": ("features", "data"), "targets": ("targets", "data")},
    "seq_order_control_dataset": "targets",
}
device = "gpu"
extern_data = {"data": {"dim": 1}, "targets": {"dim": 79, "sparse": True}}
gradient_clip = 0.0
gradient_noise = 0.0
learning_rate_file = "learning_rates"
learning_rates = [
    5e-06,
    9.5e-06,
    1.4000000000000001e-05,
    1.85e-05,
    2.3e-05,
    2.75e-05,
    3.2e-05,
    3.65e-05,
    4.1e-05,
    4.55e-05,
    5e-05,
    5.45e-05,
    5.9e-05,
    6.35e-05,
    6.8e-05,
    7.25e-05,
    7.7e-05,
    8.15e-05,
    8.6e-05,
    9.05e-05,
    9.5e-05,
    9.95e-05,
    0.00010400000000000001,
    0.00010850000000000001,
    0.000113,
    0.0001175,
    0.000122,
    0.0001265,
    0.000131,
    0.00013550000000000001,
    0.00014000000000000001,
    0.00014450000000000002,
    0.00014900000000000002,
    0.00015350000000000002,
    0.00015800000000000002,
    0.00016250000000000002,
    0.00016700000000000002,
    0.00017150000000000002,
    0.00017600000000000002,
    0.00018050000000000002,
    0.00018500000000000002,
    0.00018950000000000003,
    0.00019400000000000003,
    0.00019850000000000003,
    0.00020300000000000003,
    0.00020750000000000003,
    0.00021200000000000003,
    0.00021650000000000003,
    0.000221,
    0.0002255,
    0.00023,
    0.0002345,
    0.000239,
    0.0002435,
    0.000248,
    0.0002525,
    0.000257,
    0.0002615,
    0.000266,
    0.0002705,
    0.000275,
    0.0002795,
    0.000284,
    0.0002885,
    0.000293,
    0.0002975,
    0.000302,
    0.0003065,
    0.000311,
    0.0003155,
    0.00032,
    0.00032450000000000003,
    0.00032900000000000003,
    0.00033350000000000003,
    0.00033800000000000003,
    0.00034250000000000003,
    0.00034700000000000003,
    0.00035150000000000003,
    0.00035600000000000003,
    0.00036050000000000003,
    0.00036500000000000004,
    0.00036950000000000004,
    0.00037400000000000004,
    0.00037850000000000004,
    0.00038300000000000004,
    0.00038750000000000004,
    0.00039200000000000004,
    0.00039650000000000004,
    0.00040100000000000004,
    0.00040550000000000004,
    0.00041000000000000005,
    0.00041450000000000005,
    0.00041900000000000005,
    0.00042350000000000005,
    0.00042800000000000005,
    0.00043250000000000005,
    0.000437,
    0.0004415,
    0.000446,
    0.0004505,
    0.000455,
    0.0004595,
    0.000464,
    0.0004685,
    0.000473,
    0.0004775,
    0.000482,
    0.0004865,
    0.000491,
    0.0004955000000000001,
    0.0005,
    0.0004959090909090909,
    0.0004918181818181818,
    0.00048772727272727276,
    0.00048363636363636366,
    0.00047954545454545456,
    0.00047545454545454545,
    0.00047136363636363635,
    0.0004672727272727273,
    0.0004631818181818182,
    0.0004590909090909091,
    0.000455,
    0.0004509090909090909,
    0.00044681818181818185,
    0.00044272727272727275,
    0.00043863636363636365,
    0.00043454545454545455,
    0.0004304545454545455,
    0.0004263636363636364,
    0.0004222727272727273,
    0.0004181818181818182,
    0.0004140909090909091,
    0.00041,
    0.00040590909090909094,
    0.00040181818181818184,
    0.00039772727272727274,
    0.00039363636363636364,
    0.0003895454545454546,
    0.0003854545454545455,
    0.0003813636363636364,
    0.0003772727272727273,
    0.0003731818181818182,
    0.0003690909090909091,
    0.000365,
    0.00036090909090909093,
    0.00035681818181818183,
    0.0003527272727272728,
    0.0003486363636363637,
    0.0003445454545454546,
    0.0003404545454545455,
    0.0003363636363636364,
    0.0003322727272727273,
    0.0003281818181818182,
    0.0003240909090909091,
    0.00032,
    0.0003159090909090909,
    0.0003118181818181819,
    0.0003077272727272728,
    0.0003036363636363637,
    0.00029954545454545457,
    0.00029545454545454547,
    0.00029136363636363637,
    0.00028727272727272727,
    0.0002831818181818182,
    0.0002790909090909091,
    0.000275,
    0.00027090909090909097,
    0.00026681818181818187,
    0.00026272727272727277,
    0.00025863636363636366,
    0.00025454545454545456,
    0.00025045454545454546,
    0.0002463636363636364,
    0.0002422727272727273,
    0.0002381818181818182,
    0.0002340909090909091,
    0.00023,
    0.00022590909090909096,
    0.00022181818181818186,
    0.00021772727272727276,
    0.00021363636363636365,
    0.00020954545454545455,
    0.0002054545454545455,
    0.0002013636363636364,
    0.0001972727272727273,
    0.0001931818181818182,
    0.0001890909090909091,
    0.00018500000000000005,
    0.00018090909090909095,
    0.00017681818181818185,
    0.00017272727272727275,
    0.00016863636363636364,
    0.0001645454545454546,
    0.0001604545454545455,
    0.0001563636363636364,
    0.0001522727272727273,
    0.0001481818181818182,
    0.00014409090909090914,
    0.00014000000000000004,
    0.00013590909090909094,
    0.00013181818181818184,
    0.00012772727272727274,
    0.0001236363636363637,
    0.00011954545454545459,
    0.00011545454545454549,
    0.00011136363636363638,
    0.00010727272727272734,
    0.00010318181818181824,
    9.909090909090913e-05,
    9.500000000000003e-05,
    9.090909090909093e-05,
    8.681818181818188e-05,
    8.272727272727278e-05,
    7.863636363636368e-05,
    7.454545454545458e-05,
    7.045454545454548e-05,
    6.636363636363643e-05,
    6.227272727272733e-05,
    5.8181818181818226e-05,
    5.4090909090909124e-05,
    5e-05,
    4.827620689655173e-05,
    4.655241379310345e-05,
    4.4828620689655175e-05,
    4.31048275862069e-05,
    4.1381034482758624e-05,
    3.965724137931035e-05,
    3.793344827586207e-05,
    3.62096551724138e-05,
    3.448586206896552e-05,
    3.276206896551724e-05,
    3.103827586206897e-05,
    2.931448275862069e-05,
    2.7590689655172415e-05,
    2.586689655172414e-05,
    2.4143103448275864e-05,
    2.241931034482759e-05,
    2.0695517241379313e-05,
    1.8971724137931034e-05,
    1.7247931034482758e-05,
    1.5524137931034483e-05,
    1.3800344827586207e-05,
    1.2076551724137931e-05,
    1.0352758620689656e-05,
    8.62896551724138e-06,
    6.905172413793104e-06,
    5.1813793103448286e-06,
    3.457586206896553e-06,
    1.7337931034482773e-06,
    1e-08,
]
log = ["./returnn.log"]
log_batch_size = True
log_verbosity = 5
max_seqs = 128
model = "/u/jxu/setups/tedlium2/2024-09-10--construct-better-neural-blocks/work/i6_core/returnn/training/ReturnnTrainingJob.2mX3iCXw4Jip/output/models/epoch"
num_epochs = 250
num_inputs = 50
num_outputs = {"targets": 79}
optimizer = {"class": "adamw", "epsilon": 1e-16, "weight_decay": 0.001}
save_interval = 1
target = "targets"
task = "train"
tf_log_memory_usage = True
train = {
    "class": "MetaDataset",
    "datasets": {
        "features": {
            "class": "HDFDataset",
            "use_cache_manager": True,
            "files": [
                "/u/jxu/setups/tedlium2/2024-09-10--construct-better-neural-blocks/work/i6_core/returnn/hdf/BlissToPcmHDFJob.T3qQ5mfrQwlw/output/audio.hdf"
            ],
        },
        "targets": {
            "class": "HDFDataset",
            "use_cache_manager": True,
            "files": [
                "/u/jxu/setups/tedlium2/2024-09-10--construct-better-neural-blocks/work/i6_experiments/users/berger/recipe/returnn/hdf/BlissCorpusToTargetHdfJob.bAoRzty8czAI/output/targets.hdf"
            ],
            "partition_epoch": 5,
            "seq_ordering": "laplace:.1000",
        },
    },
    "data_map": {"data": ("features", "data"), "targets": ("targets", "data")},
    "seq_order_control_dataset": "targets",
}
update_on_device = True
window = 1
config = {}

locals().update(**config)

import os
import sys

sys.path.insert(
    0, "/u/jxu/setups/tedlium2/2024-09-10--construct-better-neural-blocks/recipe"
)
from i6_experiments.users.jxu.experiments.ctc.tedlium2.pytorch_networks.neural_block.dynamic_adaptable_e_branchformer.adapt_based_on_gradient_ranking_finer_granul_double_and_prune import (
    EbranchformerCTCModel,
)
from i6_experiments.users.jxu.experiments.ctc.tedlium2.pytorch_networks.neural_block.dynamic_adaptable_e_branchformer.adapt_based_on_gradient_ranking_finer_granul_double_and_prune import (
    EbranchformerCTCConfig,
)
from i6_models.primitives.feature_extraction import LogMelFeatureExtractionV1Config
from i6_models.assemblies.dynamic_adaptable_e_branchformer.e_branchformer_v1 import (
    EbranchformerEncoderV1Config,
)
from i6_models.parts.frontend.vgg_act import VGG4LayerActFrontendV1Config
from torch.nn.modules.activation import ReLU
from i6_models.parts.frontend.vgg_act import VGG4LayerActFrontendV1
from i6_models.config import ModuleFactoryV1
from i6_experiments.users.jxu.experiments.ctc.tedlium2.pytorch_networks.neural_block.dynamic_adaptable_e_branchformer.adapt_based_on_gradient_ranking_finer_granul_double_and_prune import (
    train_step,
)
from i6_models.assemblies.dynamic_adaptable_e_branchformer.e_branchformer_v1 import (
    EbranchformerBlockV1Config,
)
from torch.nn import SiLU
from i6_models.parts.dynamic_adaptable_conformer import ConformerMHSAV1Config
from i6_models.parts.dynamic_adaptable_conformer import (
    ConformerPositionwiseFeedForwardV1Config,
)
from i6_models.parts.dynamic_adaptable_e_branchformer import (
    ConvolutionalGatingMLPV1Config,
)
from i6_models.parts.dynamic_adaptable_e_branchformer import MergerV1Config

cfg = EbranchformerCTCConfig(
    feature_extraction_cfg=LogMelFeatureExtractionV1Config(
        sample_rate=16000,
        win_size=0.025,
        hop_size=0.01,
        f_min=60,
        f_max=7600,
        min_amp=1e-10,
        num_filters=80,
        center=False,
        n_fft=400,
    ),
    specaug_args={
        "time_min_num_masks": 2,
        "time_max_mask_per_n_frames": 25,
        "time_mask_max_size": 20,
        "freq_min_num_masks": 2,
        "freq_mask_max_size": 5,
        "freq_max_num_masks": 16,
    },
    e_branchformer_cfg=EbranchformerEncoderV1Config(
        num_layers=12,
        frontend=ModuleFactoryV1(
            module_class=VGG4LayerActFrontendV1,
            cfg=VGG4LayerActFrontendV1Config(
                in_features=80,
                conv1_channels=32,
                conv2_channels=64,
                conv3_channels=64,
                conv4_channels=32,
                conv_kernel_size=(3, 3),
                conv_padding=None,
                pool1_kernel_size=(2, 1),
                pool1_stride=(2, 1),
                pool1_padding=None,
                pool2_kernel_size=(2, 1),
                pool2_stride=(2, 1),
                pool2_padding=None,
                activation=ReLU(),
                out_features=512,
            ),
        ),
        block_cfgs=[
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
            EbranchformerBlockV1Config(
                ff1_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                ff2_cfg=ConformerPositionwiseFeedForwardV1Config(
                    input_dim=512, hidden_dim=2048, dropout=0.1, activation=SiLU()
                ),
                mhsa_cfg=ConformerMHSAV1Config(
                    input_dim=512,
                    num_att_heads=8,
                    att_head_dim=64,
                    att_weights_dropout=0.1,
                    dropout=0.1,
                ),
                cgmlp_cfg=ConvolutionalGatingMLPV1Config(
                    input_dim=512,
                    hidden_dim=3072,
                    kernel_size=31,
                    dropout=0.1,
                    activation=SiLU(),
                ),
                merger_cfg=MergerV1Config(input_dim=512, kernel_size=31, dropout=0.1),
                adjust_dropout=True,
            ),
        ],
    ),
    final_dropout=0.2,
    target_size=79,
    grad_score_opts={
        "grad_score_update_steps": 1000,
        "grad_score_metric": "first_taylor",
        "grad_update_beta": 0.1,
    },
    adaptation_opts={
        "adaptation_global_step": [60000],
        "total_cost": 100176527,
        "rest_cost": 8145551,
        "lst_replace_pct": [0.2],
        "dict_module_cost": {
            "ff1": 525184,
            "cgmlp": 604032,
            "mhsa": 131456,
            "ff2": 525184,
        },
    },
    component_dist={
        "ff1": [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],
        "cgmlp": [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],
        "mhsa": [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
        "ff2": [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],
    },
    total_num_components=240,
    lst_cmp_cost=[
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        525184,
        604032,
        604032,
        604032,
        604032,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        131456,
        525184,
        525184,
        525184,
        525184,
    ],
)

model_kwargs = {"cfg": cfg}


def get_model(epoch, step, **kwargs):
    return EbranchformerCTCModel(epoch=epoch, step=step, **model_kwargs, **kwargs)
