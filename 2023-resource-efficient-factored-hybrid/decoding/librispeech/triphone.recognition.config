[*]
configuration.channel    = output-channel
dot.channel              = nil
encoding                 = UTF-8
error.channel            = output-channel, stderr
log.channel              = output-channel
progress.channel         = output-channel
python-home              = /work/tools/asr/python/3.8.0
python-program-name      = /work/tools/asr/python/3.8.0/bin/python3.8
real-time-factor.channel = output-channel
statistics.channel       = output-channel
system-info.channel      = output-channel
time.channel             = output-channel
version.channel          = output-channel
warning.channel          = output-channel, stderr

[*.output-channel]
append     = no
compressed = no
file       = $(LOGFILE)
unbuffered = no

[*.session]
inter-op-parallelism-threads = 1
intra-op-parallelism-threads = 4

[flf-lattice-tool.corpus]
capitalize-transcriptions      = no
file                           = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/audio/encoding/BlissChangeEncodingJob.JXZDXuAtXDFI/output/corpus.xml.gz
progress-indication            = global
segments.file                  = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/corpus/segments/SegmentCorpusJob.ZHIn6OXJaEMR/output/segments.$(TASK)
warn-about-unexpected-elements = yes

[flf-lattice-tool.global-cache]
file      = `cf /u/mgunz/setups/2023-04--tf2-test/work/i6_core/recognition/advanced_tree_search/AdvancedTreeSearchLmImageAndGlobalCacheJob.1yPlBaNj6oBy/output/global.cache`
read-only = yes

[flf-lattice-tool.lexicon]
file                    = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/lexicon/modification/MergeLexiconJob.z54fVoMlr0md/output/lexicon.xml.gz
normalize-pronunciation = yes

[flf-lattice-tool.network]
initial-nodes = segment

[flf-lattice-tool.network.archive-writer]
format = flf
info   = yes
links  = sink:1
path   = lattice.cache.$(TASK)
type   = archive-writer

[flf-lattice-tool.network.evaluator]
best-in-lattice = yes
links           = sink:0
single-best     = yes
type            = evaluator
word-errors     = yes

[flf-lattice-tool.network.evaluator.edit-distance]
allow-broken-words = no
format             = bliss

[flf-lattice-tool.network.expand]
links = evaluator archive-writer
type  = expand-transits

[flf-lattice-tool.network.recognizer]
add-confidence-score          = no
apply-non-word-closure-filter = no
apply-posterior-pruning       = no
links                         = expand
pronunciation-scale           = 2.0
search-type                   = advanced-tree-search
type                          = recognizer

[flf-lattice-tool.network.recognizer.acoustic-model.allophones]
add-all          = yes
add-from-lexicon = no

[flf-lattice-tool.network.recognizer.acoustic-model.hmm]
across-word-model   = yes
early-recombination = no
state-repetitions   = 1
states-per-phone    = 3

[flf-lattice-tool.network.recognizer.acoustic-model.mixture-set]
center-state-prior-file   = /u/mgunz/setups/2023-04--tf2-test/work/i6_experiments/users/gunz/setups/fh/priors/smoothen/SmoothenPriorsJob.lxiGOWiWz05r/output/priors.xml
center-state-prior-scale  = 0.4
center-state-scale        = 1.0
context-type              = triphone-forward
feature-scorer-type       = tf-factored-hybrid-scorer
file                      = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/mm/mixtures/CreateDummyMixturesJob.GkSufDmoBSiX/output/dummy.mix
forward-scale             = 1.0
is-batch-major            = yes
is-min-duration           = no
is-multi-encoder-output   = no
left-context-prior-file   = /u/mgunz/setups/2023-04--tf2-test/work/i6_experiments/users/gunz/setups/fh/priors/smoothen/SmoothenPriorsJob.7qn6DF28XGR7/output/priors.xml
left-context-prior-scale  = 0.4
left-context-scale        = 1.0
loop-scale                = 1.0
num-encoder-output        = 512
num-label-contexts        = 42
num-states-per-phone      = 3
right-context-prior-file  = /u/mgunz/setups/2023-04--tf2-test/work/i6_experiments/users/gunz/setups/fh/priors/smoothen/SmoothenPriorsJob.nzEu6GsmgYCV/output/priors.xml
right-context-prior-scale = 0.2
right-context-scale       = 1.0
silence-forward-penalty   = 0.0
silence-id                = 40
silence-loop-penalty      = 0.0
use-boundary-classes      = no
use-estimated-tdps        = no
use-word-end-classes      = yes

[flf-lattice-tool.network.recognizer.acoustic-model.mixture-set.input-map.info-0]
param-name  = encoder-output
tensor-name = length_masked/strided_slice

[flf-lattice-tool.network.recognizer.acoustic-model.mixture-set.input-map.info-1]
param-name  = dense-classes
tensor-name = extern_data/placeholders/classes/classes

[flf-lattice-tool.network.recognizer.acoustic-model.mixture-set.loader]
meta-graph-file    = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/compile/CompileTFGraphJob.BDOfM19aE9nw/output/graph.meta
required-libraries = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/compile/CompileNativeOpJob.2dl6N7hxXz27/output/GradOfLstmGenericBase.so:/u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/compile/CompileNativeOpJob.2dl6N7hxXz27/output/LstmGenericBase.so
saved-model-file   = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/rasr_training/ReturnnRasrTrainingJob.ioels4lt7xHK/output/models/epoch.600
type               = meta

[flf-lattice-tool.network.recognizer.acoustic-model.mixture-set.output-map.info-0]
param-name  = right-context-posteriors
tensor-name = right__output/output_batch_major

[flf-lattice-tool.network.recognizer.acoustic-model.mixture-set.output-map.info-1]
param-name  = center-state-posteriors
tensor-name = center__output/output_batch_major

[flf-lattice-tool.network.recognizer.acoustic-model.mixture-set.output-map.info-2]
param-name  = left-context-posteriors
tensor-name = left__output/output_batch_major

[flf-lattice-tool.network.recognizer.acoustic-model.state-tying]
type                 = no-tying-dense
use-boundary-classes = no
use-word-end-classes = yes

[flf-lattice-tool.network.recognizer.acoustic-model.tdp]
entry-m1.loop  = infinity
entry-m2.loop  = infinity
nonword-phones = [UNKNOWN]
scale          = 0.6
tying-type     = global-and-nonword

[flf-lattice-tool.network.recognizer.acoustic-model.tdp.*]
exit    = 0.0
forward = 0.0
loop    = 3.0
skip    = infinity

[flf-lattice-tool.network.recognizer.acoustic-model.tdp.nonword-0]
exit    = 20.0
forward = 3.0
loop    = 0.0
skip    = infinity

[flf-lattice-tool.network.recognizer.acoustic-model.tdp.nonword-1]
exit    = 20.0
forward = 3.0
loop    = 0.0
skip    = infinity

[flf-lattice-tool.network.recognizer.acoustic-model.tdp.silence]
exit    = 20.0
forward = 3.0
loop    = 0.0
skip    = infinity

[flf-lattice-tool.network.recognizer.feature-extraction]
file = feature.flow

[flf-lattice-tool.network.recognizer.feature-extraction.tf-fwd.input-map.info-0]
param-name             = features
seq-length-tensor-name = extern_data/placeholders/centerState/centerState_dim0_size
tensor-name            = extern_data/placeholders/data/data

[flf-lattice-tool.network.recognizer.feature-extraction.tf-fwd.loader]
meta-graph-file    = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/compile/CompileTFGraphJob.BDOfM19aE9nw/output/graph.meta
required-libraries = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/compile/CompileNativeOpJob.2dl6N7hxXz27/output/GradOfLstmGenericBase.so:/u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/compile/CompileNativeOpJob.2dl6N7hxXz27/output/LstmGenericBase.so
saved-model-file   = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/rasr_training/ReturnnRasrTrainingJob.ioels4lt7xHK/output/models/epoch.600
type               = meta

[flf-lattice-tool.network.recognizer.feature-extraction.tf-fwd.output-map.info-0]
param-name  = encoder-output
tensor-name = encoder__output/output_batch_major

[flf-lattice-tool.network.recognizer.lm]
allow-reduced-history   = yes
max-batch-size          = 64
min-batch-size          = 0
opt-batch-size          = 64
scale                   = 13.0
transform-output-negate = yes
type                    = tfrnn
vocab-file              = /work/asr3/raissi/shared_workspaces/gunz/dependencies/ls-eugen-trafo-lm/vocabulary
vocab-unknown-word      = <UNK>

[flf-lattice-tool.network.recognizer.lm.input-map.info-0]
param-name             = word
seq-length-tensor-name = extern_data/placeholders/delayed/delayed_dim0_size
tensor-name            = extern_data/placeholders/delayed/delayed

[flf-lattice-tool.network.recognizer.lm.input-map.info-1]
param-name  = state-lengths
tensor-name = output/rec/dec_0_self_att_att/state_lengths

[flf-lattice-tool.network.recognizer.lm.loader]
meta-graph-file    = /work/asr3/raissi/shared_workspaces/gunz/dependencies/ls-eugen-trafo-lm/graph.meta
required-libraries = /u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/compile/CompileNativeOpJob.2dl6N7hxXz27/output/GradOfLstmGenericBase.so:/u/mgunz/setups/2023-04--tf2-test/work/i6_core/returnn/compile/CompileNativeOpJob.2dl6N7hxXz27/output/LstmGenericBase.so
saved-model-file   = /work/asr3/raissi/shared_workspaces/gunz/dependencies/ls-eugen-trafo-lm/epoch.030
type               = meta

[flf-lattice-tool.network.recognizer.lm.nn-output-compression]
bits-per-val = 16
epsilon      = 0.001
type         = fixed-quantization

[flf-lattice-tool.network.recognizer.lm.output-map.info-0]
param-name  = softmax
tensor-name = output/rec/decoder/add

[flf-lattice-tool.network.recognizer.lm.output-map.info-1]
param-name  = weights
tensor-name = output/rec/output/W/read

[flf-lattice-tool.network.recognizer.lm.output-map.info-2]
param-name  = bias
tensor-name = output/rec/output/b/read

[flf-lattice-tool.network.recognizer.lm.softmax-adapter]
type                 = quantized-blas-nce-16bit
weights-bias-epsilon = 0.001

[flf-lattice-tool.network.recognizer.lm.state-compression]
bits-per-val = 16
epsilon      = 0.001
type         = fixed-quantization

[flf-lattice-tool.network.recognizer.lm.state-manager]
cache-prefix             = yes
min-batch-size           = 0
min-common-prefix-length = 0
type                     = transformer-with-common-prefix-16bit

[flf-lattice-tool.network.recognizer.lm.state-manager.var-map.item-0]
common-prefix-initial-value = output/rec/dec_0_self_att_att/zeros_1:0
common-prefix-initializer   = output/rec/dec_0_self_att_att/common_prefix/Assign:0
var-name                    = output/rec/dec_0_self_att_att/keep_state_var:0

[flf-lattice-tool.network.recognizer.lm.state-manager.var-map.item-1]
common-prefix-initial-value = output/rec/dec_1_self_att_att/zeros_1:0
common-prefix-initializer   = output/rec/dec_1_self_att_att/common_prefix/Assign:0
var-name                    = output/rec/dec_1_self_att_att/keep_state_var:0

[flf-lattice-tool.network.recognizer.lm.state-manager.var-map.item-2]
common-prefix-initial-value = output/rec/dec_2_self_att_att/zeros_1:0
common-prefix-initializer   = output/rec/dec_2_self_att_att/common_prefix/Assign:0
var-name                    = output/rec/dec_2_self_att_att/keep_state_var:0

[flf-lattice-tool.network.recognizer.lm.state-manager.var-map.item-3]
common-prefix-initial-value = output/rec/dec_3_self_att_att/zeros_1:0
common-prefix-initializer   = output/rec/dec_3_self_att_att/common_prefix/Assign:0
var-name                    = output/rec/dec_3_self_att_att/keep_state_var:0

[flf-lattice-tool.network.recognizer.lm.state-manager.var-map.item-4]
common-prefix-initial-value = output/rec/dec_4_self_att_att/zeros_1:0
common-prefix-initializer   = output/rec/dec_4_self_att_att/common_prefix/Assign:0
var-name                    = output/rec/dec_4_self_att_att/keep_state_var:0

[flf-lattice-tool.network.recognizer.lm.state-manager.var-map.item-5]
common-prefix-initial-value = output/rec/dec_5_self_att_att/zeros_1:0
common-prefix-initializer   = output/rec/dec_5_self_att_att/common_prefix/Assign:0
var-name                    = output/rec/dec_5_self_att_att/keep_state_var:0

[flf-lattice-tool.network.recognizer.recognizer]
beam-pruning           = 20
beam-pruning-limit     = 500000
create-lattice         = yes
lm-lookahead           = yes
lm-lookahead-laziness  = 15
optimize-lattice       = simple
word-end-pruning       = 0.5
word-end-pruning-limit = 10000

[flf-lattice-tool.network.recognizer.recognizer.lm-lookahead]
cache-size-high        = 3000
cache-size-low         = 2000
history-limit          = 1
minimum-representation = 1
tree-cutoff            = 30

[flf-lattice-tool.network.segment]
links = 1->recognizer:1 0->archive-writer:1 0->evaluator:1
type  = speech-segment

[flf-lattice-tool.network.sink]
error-on-empty-lattice = no
type                   = sink
warn-on-empty-lattice  = yes