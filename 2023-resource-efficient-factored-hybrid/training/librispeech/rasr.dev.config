[*]
configuration.channel    = output-channel
dot.channel              = nil
encoding                 = UTF-8
error.channel            = output-channel, stderr
log.channel              = output-channel
progress.channel         = output-channel
python-home              = /work/tools/asr/python/3.8.0
python-program-name      = /work/tools/asr/python/3.8.0/bin/python3.8
real-time-factor.channel = output-channel
statistics.channel       = output-channel
system-info.channel      = output-channel
time.channel             = output-channel
version.channel          = output-channel
warning.channel          = output-channel, stderr

[*.output-channel]
append     = no
compressed = no
file       = $(LOGFILE)
unbuffered = no

[neural-network-trainer]
action                    = python-control
buffer-size               = 204800
buffer-type               = utterance
class-labels.save-to-file = class.labels
estimator                 = steepest-descent
extract-alignments        = yes
feature-extraction.file   = feature.flow
python-control-enabled    = yes
python-control-loop-type  = iterate-corpus
regression-window-size    = 5
shuffle                   = no
silence-weight            = 1.0
single-precision          = yes
soft-alignments           = no
training-criterion        = cross-entropy
weighted-alignment        = no
window-size               = 1
window-size-derivatives   = 0

[neural-network-trainer.corpus]
capitalize-transcriptions                    = no
file                                         = /work/asr4/raissi/setups/librispeech/960-ls/dependencies/data/zhou-corpora/train-dev.corpus.xml
progress-indication                          = global
segment-order-shuffle                        = yes
segment-order-sort-by-time-length            = yes
segment-order-sort-by-time-length-chunk-size = 384
segments.file                                = /work/asr3/raissi/shared_workspaces/gunz/dependencies/segments/ls-segment-names-to-librispeech/ShuffleAndSplitSegmentsJob.hPMsdZr1PSjY/output/cv.segments
warn-about-unexpected-elements               = yes

[neural-network-trainer.model-combination.acoustic-model.allophones]
add-all          = no
add-from-lexicon = yes

[neural-network-trainer.model-combination.acoustic-model.hmm]
across-word-model   = yes
early-recombination = no
state-repetitions   = 1
states-per-phone    = 3

[neural-network-trainer.model-combination.acoustic-model.state-tying]
type                 = no-tying-dense
use-boundary-classes = no
use-word-end-classes = yes

[neural-network-trainer.model-combination.acoustic-model.tdp]
entry-m1.loop = infinity
entry-m2.loop = infinity
scale         = 1.0

[neural-network-trainer.model-combination.acoustic-model.tdp.*]
exit    = 0.0
forward = 0.0
loop    = 3.0
skip    = infinity

[neural-network-trainer.model-combination.acoustic-model.tdp.silence]
exit    = 20.0
forward = 3.0
loop    = 0.0
skip    = infinity

[neural-network-trainer.model-combination.lexicon]
file                    = `cf /u/mgunz/setups/2023-04--thesis-baselines/work/i6_core/g2p/convert/G2POutputToBlissLexiconJob.JOqKFQpjp04H/output/oov.lexicon.gz`
normalize-pronunciation = yes