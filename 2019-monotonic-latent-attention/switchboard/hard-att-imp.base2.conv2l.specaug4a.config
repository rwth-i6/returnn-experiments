#!crnn/rnn.py
# kate: syntax python;

# via:
# /u/irie/setups/switchboard/2018-02-13--end2end-zeyer/config-train/bpe_1k.multihead-mlp-h1.red8.enc6l.encdrop03.decbs.ls01.pretrain2.nbd07.config
# Kazuki BPE1k baseline, from Interspeech paper.

import os
import numpy
from subprocess import check_output, CalledProcessError
from Pretrain import WrapEpochValue

# task
use_tensorflow = True
task = config.value("task", "train")
device = "gpu"
multiprocessing = True
update_on_device = True

debug_mode = False
if int(os.environ.get("DEBUG", "0")):
    print("** DEBUG MODE")
    debug_mode = True

if config.has("beam_size"):
    beam_size = config.int("beam_size", 0)
    print("** beam_size %i" % beam_size)
else:
    if task == "train":
        beam_size = 4
    else:
        beam_size = 12

_cf_cache = {}

def cf(filename):
    """Cache manager"""
    if filename in _cf_cache:
        return _cf_cache[filename]
    if debug_mode or check_output(["hostname"]).strip().decode("utf8") in ["cluster-cn-211", "sulfid"]:
        print("use local file: %s" % filename)
        return filename  # for debugging
    try:
        cached_fn = check_output(["cf", filename]).strip().decode("utf8")
    except CalledProcessError:
        print("Cache manager: Error occured, using local file")
        return filename
    assert os.path.exists(cached_fn)
    _cf_cache[filename] = cached_fn
    return cached_fn

# data
target = "bpe"
extern_data = {
    "data": {"dim": 40},  # Gammatone 40-dim
    target: {"dim": 1030, "sparse": True},  # see vocab
    "alignment": {"dim": None, "shape": (None,), "dtype": "int32", "sparse": True},
    "align_score": {"shape": (1,), "dtype": "float32"},
}
EpochSplit = 6

def get_sprint_dataset(data, hdf_files=None):
    assert data in {"train", "cv", "dev", "hub5e_01", "rt03s"}
    epoch_split = {"train": EpochSplit}.get(data, 1)
    corpus_name = {"cv": "train"}.get(data, data)  # train, dev, hub5e_01, rt03s

    # see /u/tuske/work/ASR/switchboard/corpus/readme
    # and zoltans mail https://mail.google.com/mail/u/0/#inbox/152891802cbb2b40
    files = {}
    files["config"] = "config/training.config"
    files["corpus"] = "/work/asr3/irie/data/switchboard/corpora/%s.corpus.gz" % corpus_name
    if data in {"train", "cv"}:
        files["segments"] = "dependencies/seg_%s" % {"train":"train", "cv":"cv_head3000"}[data]
    files["features"] = "/u/tuske/work/ASR/switchboard/feature.extraction/gt40_40/data/gt.%s.bundle" % corpus_name
    for k, v in sorted(files.items()):
        assert os.path.exists(v), "%s %r does not exist" % (k, v)
    estimated_num_seqs = {"train": 227047, "cv": 3000}  # wc -l segment-file

    args = [
        "--config=" + files["config"],
        lambda: "--*.corpus.file=" + cf(files["corpus"]),
        lambda: "--*.corpus.segments.file=" + (cf(files["segments"]) if "segments" in files else ""),
        lambda: "--*.feature-cache-path=" + cf(files["features"]),
        "--*.log-channel.file=/dev/null",
        "--*.window-size=1",
    ]
    if not hdf_files:
        args += [
            "--*.corpus.segment-order-shuffle=true",
            "--*.segment-order-sort-by-time-length=true",
            "--*.segment-order-sort-by-time-length-chunk-size=%i" % {"train": epoch_split * 1000}.get(data, -1),
        ]
    d = {
        "class": "ExternSprintDataset", "sprintTrainerExecPath": "sprint-executables/nn-trainer",
        "sprintConfigStr": args,
        "suppress_load_seqs_print": True,  # less verbose
    }
    d.update(sprint_interface_dataset_opts)
    partition_epochs_opts = {
        "partition_epoch": epoch_split,
        "estimated_num_seqs": (estimated_num_seqs[data] // epoch_split) if data in estimated_num_seqs else None,
    }
    if hdf_files:
        align_opts = {
            "class": "HDFDataset", "files": hdf_files,
            "seq_list_filter_file": files["segments"],  # otherwise not right selection
            "unique_seq_tags": True  # dev set can exist multiple times
            }
        align_opts.update(partition_epochs_opts)  # this dataset will control the seq list
        d = {
            "class": "MetaDataset",
            "datasets": {"sprint": d, "align": align_opts},
            "data_map": {
                "data": ("sprint", "data"),
                target: ("sprint", target),
                "alignment": ("align", "data"),
                "align_score": ("align", "scores")},
            "seq_order_control_dataset": "align",  # it must support get_all_tags
        }
    else:
        d.update(partition_epochs_opts)
    return d

sprint_interface_dataset_opts = {
    "input_stddev": 3.,
    "bpe": {
        'bpe_file': '/work/asr3/irie/data/switchboard/subword_clean/ready/swbd_clean.bpe_code_1k',
        'vocab_file': '/work/asr3/irie/data/switchboard/subword_clean/ready/vocab.swbd_clean.bpe_code_1k',
        'seq_postfix': [0]
    }}

train = get_sprint_dataset("train")
dev = get_sprint_dataset("cv")
cache_size = "0"
window = 1

# network
# (also defined by num_inputs & num_outputs)
EncKeyTotalDim = 1024
AttNumHeads = 1  # must be 1 for hard-att
EncKeyPerHeadDim = EncKeyTotalDim // AttNumHeads
EncValueTotalDim = 2048
EncValuePerHeadDim = EncValueTotalDim // AttNumHeads
LstmDim = EncValueTotalDim // 2

# Note: We control the warmup in the pretrain construction.
learning_rate = 0.001
min_learning_rate = learning_rate / 50.


def summary(name, x):
    """
    :param str name:
    :param tf.Tensor x: (batch,time,feature)
    """
    import tensorflow as tf
    # tf.summary.image wants [batch_size, height,  width, channels],
    # we have (batch, time, feature).
    img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
    img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
    tf.summary.image(name, img, max_outputs=10)
    tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
    mean = tf.reduce_mean(x)
    tf.summary.scalar("%s_mean" % name, mean)
    stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
    tf.summary.scalar("%s_stddev" % name, stddev)
    tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))


def _mask(x, batch_axis, axis, pos, max_amount):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int batch_axis:
    :param int axis:
    :param tf.Tensor pos: (batch,)
    :param int|tf.Tensor max_amount: inclusive
    """
    import tensorflow as tf
    ndim = x.get_shape().ndims
    n_batch = tf.shape(x)[batch_axis]
    dim = tf.shape(x)[axis]
    amount = tf.random_uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
    pos2 = tf.minimum(pos + amount, dim)
    idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
    pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
    pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
    cond = tf.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
    if batch_axis > axis:
        cond = tf.transpose(cond)  # (dim,batch)
    cond = tf.reshape(cond, [tf.shape(x)[i] if i in (batch_axis, axis) else 1 for i in range(ndim)])
    from TFUtil import where_bc
    x = where_bc(cond, 0.0, x)
    return x


def random_mask(x, batch_axis, axis, min_num, max_num, max_dims):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int batch_axis:
    :param int axis:
    :param int|tf.Tensor min_num:
    :param int|tf.Tensor max_num: inclusive
    :param int|tf.Tensor max_dims: inclusive
    """
    import tensorflow as tf
    n_batch = tf.shape(x)[batch_axis]
    if isinstance(min_num, int) and isinstance(max_num, int) and min_num == max_num:
        num = min_num
    else:
        num = tf.random_uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
    # https://github.com/tensorflow/tensorflow/issues/9260
    # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
    z = -tf.log(-tf.log(tf.random_uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
    _, indices = tf.nn.top_k(z, num if isinstance(num, int) else tf.reduce_max(num))
    # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
    # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
    if isinstance(num, int):
        for i in range(num):
            x = _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims)
    else:
        _, x = tf.while_loop(
            cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
            body=lambda i, x: (
                i + 1,
                tf.where(
                    tf.less(i, num),
                    _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims),
                    x)),
            loop_vars=(0, x))
    return x


def transform(data, network, time_factor=1):
    x = data.placeholder
    import tensorflow as tf
    # summary("features", x)
    step = network.global_train_step
    step1 = tf.where(tf.greater_equal(step, 1000), 1, 0)
    step2 = tf.where(tf.greater_equal(step, 2000), 1, 0)
    def get_masked():
        x_masked = x
        x_masked = random_mask(
          x_masked, batch_axis=data.batch_dim_axis, axis=data.time_dim_axis,
          min_num=step1 + step2, max_num=tf.maximum(tf.shape(x)[data.time_dim_axis] // 100, 2) * (1 + step1 + step2 * 2),
          max_dims=20 // time_factor)
        x_masked = random_mask(
          x_masked, batch_axis=data.batch_dim_axis, axis=data.feature_dim_axis,
          min_num=step1 + step2, max_num=2 + step1 + step2 * 2,
          max_dims=data.dim // 5)
        #summary("features_mask", x_masked)
        return x_masked
    x = network.cond_on_train(get_masked, lambda: x)
    return x


def t_linear(source, **kwargs):
    import tensorflow as tf
    from TFUtil import where_bc
    enc = source(1, as_data=True, auto_convert=False)
    dec = source(0, as_data=True, auto_convert=False)
    enc_lens = enc.get_sequence_lengths()
    dec_lens = dec.get_sequence_lengths()
    dec_shape = tf.shape(dec.placeholder)
    batch_dim = dec_shape[dec.batch_dim_axis]
    dec_time_dim = dec_shape[dec.time_dim_axis]
    dec_times = tf.expand_dims(tf.range(dec_time_dim), axis=0)  # (1,dec-T)
    x = tf.cast(dec_times + 1, tf.float32)  # (1,dec-T)
    # We want: x[dec_len - 1] == enc_time - 1.
    factors = tf.maximum(tf.cast(enc_lens - 1, tf.float32), 0.0) / tf.maximum(tf.cast(dec_lens, tf.float32), 1.0)  # (B,)
    factors = tf.expand_dims(factors, axis=1)  # (B,1)
    x = x * factors  # (B,dec-T)
    x = tf.cast(tf.round(x), tf.int32)
    x = tf.minimum(x, tf.expand_dims(enc_lens - 1, axis=1))
    # fix cheating gold targets with end flag filter. must be 0
    x = where_bc(tf.less(dec_times, tf.expand_dims(dec_lens, axis=1)), x, 0)
    return x

def t_search_t_loop_err(source, **kwargs):
    import tensorflow as tf
    from TFUtil import where_bc
    ts_search = source(0, as_data=True, auto_convert=False).copy_as_batch_major()  # (B,T)
    seq_lens = ts_search.get_sequence_lengths()  # (B,)
    seq_lens_bc = seq_lens[:, None]  # (B,1)
    l = tf.equal(ts_search.placeholder[:,1:], ts_search.placeholder[:,:-1])  # (B,T-1)
    l = tf.cast(l, tf.int32)  # 1 if err else 0
    l = tf.pad(l, [[0,0],[1,0]])  # (B,T)
    l = where_bc(tf.less(tf.range(tf.shape(l)[1])[None,:], seq_lens_bc), l, 0)
    l = tf.reduce_sum(l, axis=1)  # (B,)
    l = tf.cast(l, tf.float32) / tf.cast(seq_lens, tf.float32)  # (B,)
    return l

def t_search_or_fallback(source, **kwargs):
    import tensorflow as tf
    from TFUtil import where_bc
    ts_linear = source(0)  # (B,T)
    ts_search = source(1)  # (B,T)
    l = source(2, auto_convert=False)  # (B,)
    return where_bc(tf.less(l[:, None], 0.01), ts_search, ts_linear)


StoreAlignmentUpToEpoch = 10 * EpochSplit  # 0 based, exclusive
AlignmentFilenamePattern = "net-model/alignments.%i.hdf"

def get_most_recent_align_hdf_files(epoch0):
    """
    :param int epoch0: 0-based (sub) epoch
    :return: filenames or None if there is nothing completed yet
    :rtype: list[str]|None
    """
    if epoch0 < EpochSplit:
        return None
    if epoch0 > StoreAlignmentUpToEpoch:
        epoch0 = StoreAlignmentUpToEpoch  # first epoch after
    i = ((epoch0 - EpochSplit) // EpochSplit) * EpochSplit
    return [AlignmentFilenamePattern % j for j in range(i, i + EpochSplit)]


def get_net_dict(pretrain_idx):
    """
    :param int|None pretrain_idx: starts at 0. note that this has a default repetition factor of 6
    :return: net_dict or None if pretrain should stop
    :rtype: dict[str,dict[str]|int]|None
    """
    # Note: epoch0 is 0-based here! I.e. in contrast to elsewhere, where it is 1-based.
    # Also, we never use #repetition here, such that this is correct.
    # This is important because of sub-epochs and storing the HDF files,
    # to know exactly which HDF files cover the dataset completely.
    epoch0 = pretrain_idx
    net_dict = {}

    have_existing_align = False  # only in training, and only in pretrain, and only after the first epoch
    if pretrain_idx is not None:
        net_dict["#config"] = {}

        if task == "train":
            most_recent_align_hdf_files = get_most_recent_align_hdf_files(epoch0)
            have_existing_align = bool(most_recent_align_hdf_files)

            net_dict["#config"].update({
                "train": get_sprint_dataset("train", hdf_files=most_recent_align_hdf_files),
                "dev": get_sprint_dataset("cv", hdf_files=most_recent_align_hdf_files),
            })

            # Do this in the very beginning.
            lr_warmup = [0.0] * EpochSplit  # first collect alignments with existing model, no training
            lr_warmup += list(numpy.linspace(0.0001, learning_rate, num=10))
            lr_warmup += [learning_rate] * 10
            if pretrain_idx < len(lr_warmup):
                net_dict["#config"]["learning_rate"] = lr_warmup[pretrain_idx]
            pretrain_idx -= len(lr_warmup)

    use_t_search_as_target = not have_existing_align or epoch0 < StoreAlignmentUpToEpoch
    use_soft_att = pretrain_idx is not None and pretrain_idx <= 2
    use_t_start_zero = use_soft_att

    if pretrain_idx is not None:
        # First with soft att, later without. Repeat a bit.
        pretrain_idx -= 5

    # We import the model, thus no growing.
    start_num_lstm_layers = 6
    final_num_lstm_layers = 6
    num_lstm_layers = final_num_lstm_layers
    if pretrain_idx is not None:
        pretrain_idx = max(pretrain_idx, 0) // 5  # Repeat a bit.
        num_lstm_layers = pretrain_idx + start_num_lstm_layers
        pretrain_idx = num_lstm_layers - final_num_lstm_layers
        num_lstm_layers = min(num_lstm_layers, final_num_lstm_layers)

    if final_num_lstm_layers > start_num_lstm_layers:
        start_dim_factor = 0.5
        grow_frac = 1.0 - float(final_num_lstm_layers - num_lstm_layers) / (final_num_lstm_layers - start_num_lstm_layers)
        dim_frac = start_dim_factor + (1.0 - start_dim_factor) * grow_frac
    else:
        dim_frac = 1.

    time_reduction = [3, 2] if num_lstm_layers >= 2 else [6]

    if pretrain_idx is not None and pretrain_idx <= 1 and "learning_rate" not in net_dict["#config"]:
        # Fixed learning rate for the beginning.
        net_dict["#config"]["learning_rate"] = learning_rate

    net_dict["#info"] = {
        "epoch0": epoch0,  # Set this here such that a new construction for every pretrain idx is enforced in all cases.
        "num_lstm_layers": num_lstm_layers,
        "dim_frac": dim_frac,
        "have_existing_align": have_existing_align,
        "use_t_search_as_target": use_t_search_as_target,
        "use_soft_att": use_soft_att,
        "use_t_start_zero": use_t_start_zero,
    }

    # We use this pretrain construction during the whole training time (epoch0 > num_epochs).
    if pretrain_idx is not None and epoch0 % EpochSplit == 0 and epoch0 > num_epochs:
        # Stop pretraining now.
        return None

    net_dict.update({
        "source": {"class": "eval", "eval": "self.network.get_config().typed_value('transform')(source(0, as_data=True), network=self.network)"},
        "source0": {"class": "split_dims", "axis": "F", "dims": (-1, 1), "from": "source"},  # (T,40,1)

        # Lingvo: ep.conv_filter_shapes = [(3, 3, 1, 32), (3, 3, 32, 32)],  ep.conv_filter_strides = [(2, 2), (2, 2)]
        "conv0": {"class": "conv", "from": "source0", "padding": "same", "filter_size": (3, 3), "n_out": 32, "activation": None, "with_bias": True},  # (T,40,32)
        "conv0p": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (1, 2), "from": "conv0"},  # (T,20,32)
        "conv1": {"class": "conv", "from": "conv0p", "padding": "same", "filter_size": (3, 3), "n_out": 32, "activation": None, "with_bias": True},  # (T,20,32)
        "conv1p": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (1, 2), "from": "conv1"},  # (T,10,32)
        "conv_merged": {"class": "merge_dims", "from": "conv1p", "axes": "static"},  # (T,320)

        # Encoder LSTMs added below, resulting in "encoder0".

        #"encoder": {"class": "postfix_in_time", "postfix": 0.0, "from": "encoder0"},
        "encoder": {"class": "copy", "from": "encoder0"},
        
        "enc_ctx": {"class": "linear", "activation": None, "with_bias": True, "from": ["encoder"], "n_out": EncKeyTotalDim},
        "enc_value": {"class": "copy", "from": "encoder"},  # (B, enc-T, D)
        "enc_seq_len": {"class": "length", "from": "encoder", "sparse": True},

        # for task "search" / search_output_layer
        "decision": {
            "class": "decide", "from": "output", "loss": "edit_distance", "target": target,
            'only_on_search': True},

        "t_linear": {
            "class": "eval", "from": ["data:%s" % target, "encoder"], "eval": t_linear,
            "out_type": {"batch_dim_axis": 0, "time_dim_axis": 1, "shape": (None,), "sparse": True, "dtype": "int32", "dim": None},
            "size_target": target},

        # Target for decoder ('output') with search ("extra.search") in training.
        # The layer name must be smaller than "t_target" such that this is created first.
        "1_t_base": {
            "class": "copy",
            "from": "existing_alignment" if have_existing_align else "t_linear",
            "register_as_extern_data": "t_base"},

        "2_t_target": {
            "class": "copy",
            "from": "extra.search:t_search_or_fallback" if use_t_search_as_target else "data:t_base",
            "register_as_extern_data": "t_target" if task == "train" else None},

        #"ctc": {"class": "softmax", "from": "encoder", "loss": "ctc", "target": target,
        #    "loss_opts": {"beam_width": 1, "use_native": True}},
    })

    if have_existing_align:
        net_dict.update({
            # This should be compatible to t_linear or t_search.
            "existing_alignment": {
                "class": "reinterpret_data", "from": "data:alignment",
                "set_sparse": True,  # not sure what the HDF gives us
                "set_sparse_dim": None,
                "size_base": "data:%s" % target,
                },
            # This should be compatible to search_score.
            "existing_align_score": {
                "class": "squeeze", "from": "data:align_score", "axis": "f",
                "loss": "as_is", "loss_scale": 0
                }
            })

    # Add encoder BLSTM stack.
    src = "conv_merged"
    if num_lstm_layers >= 1:
        net_dict.update({
            "lstm0_fw": {"class": "rec", "unit": "nativelstm2", "n_out": int(LstmDim * dim_frac), "direction": 1, "from": src},
            "lstm0_bw": {"class": "rec", "unit": "nativelstm2", "n_out": int(LstmDim * dim_frac), "direction": -1, "from": src}})
        src = ["lstm0_fw", "lstm0_bw"]
    for i in range(1, num_lstm_layers):
        red = time_reduction[i - 1] if (i - 1) < len(time_reduction) else 1
        net_dict.update({
            "lstm%i_pool" % (i - 1): {"class": "pool", "mode": "max", "padding": "same", "pool_size": (red,), "from": src}})
        src = "lstm%i_pool" % (i - 1)
        net_dict.update({
            "lstm%i_fw" % i: {"class": "rec", "unit": "nativelstm2", "n_out": int(LstmDim * dim_frac), "direction": 1, "from": src, "dropout": 0.3 * dim_frac},
            "lstm%i_bw" % i: {"class": "rec", "unit": "nativelstm2", "n_out": int(LstmDim * dim_frac), "direction": -1, "from": src, "dropout": 0.3 * dim_frac}})
        src = ["lstm%i_fw" % i, "lstm%i_bw" % i]
    net_dict["encoder0"] = {"class": "copy", "from": src}  # dim: EncValueTotalDim

    def get_output_dict(train, search, t_target, beam_size=beam_size):
        return {"class": "rec", "from": [], "back_prop": (task == "train") and train,
        "unit": {
            # TODO: weight feedback
            "s_transformed": {"class": "linear", "activation": None, "with_bias": False, "from": ["s"], "n_out": EncKeyTotalDim},
            "energy_in": {"class": "combine", "kind": "add", "from": ["base:enc_ctx", "s_transformed"], "n_out": EncKeyTotalDim},
            "energy_tanh": {"class": "activation", "activation": "tanh", "from": "energy_in"},

            "energy": {"class": "linear", "activation": None, "with_bias": False, "from": ["energy_tanh"], "n_out": AttNumHeads},  # (B, enc-T, H)
            "energy1": {"class": "squeeze", "axis": "f", "from": "energy"},  # (B, enc-T)
            "energy2": {"class": "reinterpret_data", "from": "energy1", "set_axes": {"t": "stag:lstm"}},
            "att_weights": {
                "class": "softmax_over_spatial", "from": "energy2",
                "start": None if (use_t_start_zero and not search) else "t_start"},  # (B, enc-T)
            # ChoiceLayer works on the feature axis.
            "att_weights1": {
                "class": "reinterpret_data", "from": "att_weights", "set_axes": {"f": "stag:lstm"},
                "target": t_target if (train and not use_soft_att) else None,
                "loss": "ce" if (train and not use_soft_att and t_target) else None,
            },

            "t0": {
                "class": "choice", "from": "att_weights1",
                #"target": None,
                "target": t_target, "cheating": bool(t_target),  # add this in training
                "beam_size": beam_size,
                "length_normalization": False, "initial_output": -1},  # (B,)
            # Note: If beam-size > enc_seq_len, we end up with invalid t in the beam. Fix that.
            "t1": {"class": "eval", "from": ["t0", "base:enc_seq_len"], "eval": "tf.minimum(source(0), source(1) - 1)"},
            "t": {
                #"class": "print",
                "class": "copy",
                "from": "t1", "initial_output": -1, "is_output_layer": bool(search)},

            "t_start": {
                    # Need right start for masking to avoid infs.
                    "class": "eval", "from": ["prev:t", "data:%s" % t_target],
                    "eval": "tf.minimum(source(0), source(1))"}
                    if t_target else
                    {"class": "copy", "from": "prev:t"},

            "att_hard": {"class": "gather_nd", "position": "t", "from": "base:enc_value"},  # (B, V)
            "att_soft": {"class": "generic_attention", "weights": "att_weights", "base": "base:enc_value"},  # (B, V)
            "att": {"class": "copy", "from": "att_soft"}
                   if use_soft_att and not search else {"class": "copy", "from": "att_hard"},

            "s": {"class": "rec", "unit": "nativelstm2", "from": ["prev:target_embed", "prev:att"], "n_out": 1000},
            "readout_in": {"class": "linear", "from": ["s", "prev:target_embed", "att"], "activation": None, "n_out": 1000},
            "readout": {"class": "reduce_out", "mode": "max", "num_pieces": 2, "from": ["readout_in"]},
            "output_prob": {"class": "softmax", "from": ["readout"], "dropout": 0.3, "target": target,
                "loss": "ce" if train else None},

            'target_embed': {'class': 'linear', 'activation': None, "with_bias": False, 'from': ['output'], "n_out": 621},
            'output': {
                'class': 'choice', 'target': target, 'beam_size': beam_size, 'from': ["output_prob"], "initial_output": 0,
                'search': task != 'train', "length_normalization": task != "train"},

            #"end": {"class": "compare", "from": ["t", "base:enc_seq_len"], "kind": "greater_equal"},
            "end": {"class": "compare", "from": "output", "value": 0},

            },
            "target": [target, t_target] if t_target else [target],
            "size_target": t_target,
            "max_seq_len": "max_len_from('base:encoder0')"}

    if task == "train":
        if use_t_search_as_target:
            net_dict.update({
                "extra.search:output":
                    get_output_dict(
                        train=False, search=True, t_target="t_base", beam_size=beam_size),
                "extra.search:t_search": {"class": "decide", "from": "extra.search:output/t"},
                "extra.search:search_loss": {
                    "class": "decide", "from": "extra.search:output", "loss": "search_score", "loss_scale": 0},
                "extra.search:search_score": {
                    "class": "eval", "from": "extra.search:search_loss",
                    "out_type": {"dtype": "float32", "sparse": False, "shape": (), "dim": None, "batch_dim_axis": 0, "time_dim_axis": None},
                    "eval": "(source(0, auto_convert=False), tf.squeeze(self.sources[0].search_choices.beam_scores, axis=1) / tf.cast(source(0, auto_convert=False, as_data=True).get_sequence_lengths(), tf.float32))[-1]",
                    "loss": "as_is", "loss_scale": 0},
                "t_search_t_loop_err": {
                    "class": "eval", "from": "extra.search:t_search",
                    "eval": t_search_t_loop_err,
                    "out_type": {"batch_dim_axis": 0, "time_dim_axis": None, "shape": (), "dim": None, "dtype": "float32"},
                    "loss": "as_is", "loss_scale": 0},
                "t_search_linear_err": {
                    "class": "eval", "from": ["extra.search:t_search", "t_linear"],
                    "eval": "tf.cast(tf.abs(source(0) - source(1)), tf.float32)",
                    "out_type": {"dtype": "float32", "sparse": False, "dim": None},
                    "loss": "as_is", "loss_scale": 0},
                "use_t_search":
                    {"class": "compare", "kind": "less", "from": ["existing_align_score", "extra.search:search_score"]}
                    if have_existing_align else
                    {"class": "constant", "value": True},
                "t_search_or_fallback": {
                    "class": "switch", "condition": "use_t_search",
                    "true_from": "extra.search:t_search", "false_from": "data:t_base"}
                    if have_existing_align else
                    {"class": "copy", "from": "data:t_base"},
                "t_search_or_fallback_score":
                    {"class": "switch", "condition": "use_t_search",
                     "true_from": "extra.search:search_score", "false_from": "existing_align_score"}
                    if have_existing_align else
                    {"class": "copy", "from": "extra.search:search_score"},
            })
            if epoch0 is not None and epoch0 < StoreAlignmentUpToEpoch:
                net_dict.update({
                    "extra.search:t_search_dump": {
                        "class": "hdf_dump", "from": "t_search_or_fallback",
                        "extra": {"scores": "t_search_or_fallback_score"},
                        "filename": AlignmentFilenamePattern % epoch0,
                        "is_output_layer": True},
                    })

            net_dict["extra.search:output"]["unit"].update({
              "t_base_err": {
                "class": "eval", "from": ["t", "data:t_base"], "collocate_with": "t",
                "eval": "tf.cast(tf.abs(source(0) - source(1)), tf.float32)",
                "loss": "as_is",
                "loss_scale": 0,
                "out_type": {"dtype": "float32"}},
              "t_loop_err": {
                "class": "eval", "from": ["t", "prev:t"], "collocate_with": "t",
                "eval": "where_bc(tf.equal(source(0), source(1)), 1., 0.)",
                "loss": "as_is",
                "loss_scale": 0,
                "out_type": {"dtype": "float32"}}})

        net_dict["output"] = get_output_dict(train=True, search=False, t_target="t_target")
    else:
        net_dict["output"] = get_output_dict(train=True, search=True, t_target=None)

    return net_dict


network = get_net_dict(pretrain_idx=None)
search_output_layer = "decision"
debug_print_layer_output_template = True

# trainer
batching = "random"
# Seq-length 'data' Stats:
#  37867 seqs
#  Mean: 447.397258827
#  Std dev: 350.353162012
#  Min/max: 15 / 2103
# Seq-length 'bpe' Stats:
#  37867 seqs
#  Mean: 14.1077719386
#  Std dev: 13.3402518828
#  Min/max: 2 / 82
log_batch_size = True
batch_size = 10000
max_seqs = 200
max_seq_length = {"bpe": 75}
#chunking = ""  # no chunking
truncation = -1

def custom_construction_algo(idx, net_dict):
    # For debugging, use: python3 ./crnn/Pretrain.py config...
    return get_net_dict(pretrain_idx=idx)

# No repetitions here. We explicitly do that in the construction.
pretrain = {"copy_param_mode": "subset", "construction_algo": custom_construction_algo}

import_model_train_epoch1 = "base/data-train/base2.conv2l.specaug4a/net-model/network.160"

num_epochs = 200
model = "net-model/network"
cleanup_old_models = True
gradient_clip = 0
#gradient_clip_global_norm = 1.0
adam = True
optimizer_epsilon = 1e-8
accum_grad_multiple_step = 2
#debug_add_check_numerics_ops = True
#debug_add_check_numerics_on_output = True
tf_log_memory_usage = True
gradient_noise = 0.0
# lr set above
learning_rate_control = "newbob_multi_epoch"
learning_rate_control_error_measure = "dev_error_output/output_prob"
learning_rate_control_relative_error_relative_lr = True
learning_rate_control_min_num_epochs_per_new_lr = 3
use_learning_rate_control_always = True
newbob_multi_num_epochs = 6
newbob_multi_update_interval = 1
newbob_learning_rate_decay = 0.7
learning_rate_file = "newbob.data"

# log
#log = "| /u/zeyer/dotfiles/system-tools/bin/mt-cat.py >> log/crnn.seq-train.%s.log" % task
log = "log/crnn.%s.log" % task
log_verbosity = 5



