#!crnn/rnn.py
# kate: syntax python;

# via:
# /u/irie/setups/switchboard/2018-02-13--end2end-zeyer/config-train/bpe_1k.multihead-mlp-h1.red8.enc6l.encdrop03.decbs.ls01.pretrain2.nbd07.config
# Kazuki BPE1k baseline, from Interspeech paper.

import os
import numpy
from subprocess import check_output, CalledProcessError
from Pretrain import WrapEpochValue

# task
use_tensorflow = True
task = config.value("task", "train")
device = "gpu"
multiprocessing = True
update_on_device = True

debug_mode = False
if int(os.environ.get("SETUP_DEBUG", "0")):
    print("** DEBUG MODE")
    debug_mode = True

if config.has("beam_size"):
    beam_size = config.int("beam_size", 0)
    print("** beam_size %i" % beam_size)
else:
    if task == "train":
        beam_size = 8
    else:
        beam_size = 12

_cf_cache = {}

def cf(filename):
    """Cache manager"""
    if filename in _cf_cache:
        return _cf_cache[filename]
    if debug_mode or check_output(["hostname"]).strip().decode("utf8") in ["cluster-cn-211", "sulfid"]:
        print("use local file: %s" % filename)
        return filename  # for debugging
    try:
        cached_fn = check_output(["cf", filename]).strip().decode("utf8")
    except CalledProcessError:
        print("Cache manager: Error occured, using local file")
        return filename
    assert os.path.exists(cached_fn)
    _cf_cache[filename] = cached_fn
    return cached_fn

# data
target = "bpe"
extern_data = {
    "data": {"dim": 40},  # Gammatone 40-dim
    target: {"dim": 1030, "sparse": True},  # see vocab
    "alignment": {"dim": None, "shape": (None,), "dtype": "int32", "sparse": True},
    "align_score": {"shape": (1,), "dtype": "float32"},
}
EpochSplit = 6

def get_sprint_dataset(data, hdf_files=None):
    assert data in {"train", "cv", "dev", "hub5e_01", "rt03s"}
    epoch_split = {"train": EpochSplit}.get(data, 1)
    corpus_name = {"cv": "train"}.get(data, data)  # train, dev, hub5e_01, rt03s

    # see /u/tuske/work/ASR/switchboard/corpus/readme
    # and zoltans mail https://mail.google.com/mail/u/0/#inbox/152891802cbb2b40
    files = {}
    files["config"] = "config/training.config"
    files["corpus"] = "/work/asr3/irie/data/switchboard/corpora/%s.corpus.gz" % corpus_name
    if data in {"train", "cv"}:
        files["segments"] = "dependencies/seg_%s" % {"train":"train", "cv":"cv_head3000"}[data]
    files["features"] = "/u/tuske/work/ASR/switchboard/feature.extraction/gt40_40/data/gt.%s.bundle" % corpus_name
    for k, v in sorted(files.items()):
        assert os.path.exists(v), "%s %r does not exist" % (k, v)
    estimated_num_seqs = {"train": 227047, "cv": 3000}  # wc -l segment-file

    args = [
        "--config=" + files["config"],
        lambda: "--*.corpus.file=" + cf(files["corpus"]),
        lambda: "--*.corpus.segments.file=" + (cf(files["segments"]) if "segments" in files else ""),
        lambda: "--*.feature-cache-path=" + cf(files["features"]),
        "--*.log-channel.file=/dev/null",
        "--*.window-size=1",
    ]
    if not hdf_files:
        args += [
            "--*.corpus.segment-order-shuffle=true",
            "--*.segment-order-sort-by-time-length=true",
            "--*.segment-order-sort-by-time-length-chunk-size=%i" % {"train": epoch_split * 1000}.get(data, -1),
        ]
    d = {
        "class": "ExternSprintDataset", "sprintTrainerExecPath": "sprint-executables/nn-trainer",
        "sprintConfigStr": args,
        "suppress_load_seqs_print": True,  # less verbose
    }
    d.update(sprint_interface_dataset_opts)
    partition_epochs_opts = {
        "partition_epoch": epoch_split,
        "estimated_num_seqs": (estimated_num_seqs[data] // epoch_split) if data in estimated_num_seqs else None,
    }
    if hdf_files:
        align_opts = {
            "class": "HDFDataset", "files": hdf_files,
            "seq_list_filter_file": files["segments"],  # otherwise not right selection
            "unique_seq_tags": True,  # dev set can exist multiple times
            }
        align_opts.update(partition_epochs_opts)  # this dataset will control the seq list
        if data == "train":
            align_opts["seq_ordering"] = "laplace:%i" % (estimated_num_seqs[data] // 1000)
            align_opts["seq_order_seq_lens_file"] = "/u/zeyer/setups/switchboard/dataset/data/seq-lens.train.txt.gz"
        d = {
            "class": "MetaDataset",
            "datasets": {"sprint": d, "align": align_opts},
            "data_map": {
                "data": ("sprint", "data"),
                target: ("sprint", target),
                "alignment": ("align", "data"),
                "align_score": ("align", "scores")},
            "seq_order_control_dataset": "align",  # it must support get_all_tags
        }
    else:
        d.update(partition_epochs_opts)
    return d

sprint_interface_dataset_opts = {
    "input_stddev": 3.,
    "bpe": {
        'bpe_file': '/work/asr3/irie/data/switchboard/subword_clean/ready/swbd_clean.bpe_code_1k',
        'vocab_file': '/work/asr3/irie/data/switchboard/subword_clean/ready/vocab.swbd_clean.bpe_code_1k',
        'seq_postfix': [0]
    }}

train = get_sprint_dataset("train")
dev = get_sprint_dataset("cv")
cache_size = "0"
window = 1

# network
# (also defined by num_inputs & num_outputs)
EncKeyTotalDim = 1024
AttNumHeads = 1  # must be 1 for hard-att
EncKeyPerHeadDim = EncKeyTotalDim // AttNumHeads
EncValueTotalDim = 2048
EncValuePerHeadDim = EncValueTotalDim // AttNumHeads
LstmDim = EncValueTotalDim // 2

# Note: We control the warmup in the pretrain construction.
learning_rate = 0.001
min_learning_rate = learning_rate / 50.


def summary(name, x):
    """
    :param str name:
    :param tf.Tensor x: (batch,time,feature)
    """
    import tensorflow as tf
    # tf.summary.image wants [batch_size, height,  width, channels],
    # we have (batch, time, feature).
    img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
    img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
    tf.summary.image(name, img, max_outputs=10)
    tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
    mean = tf.reduce_mean(x)
    tf.summary.scalar("%s_mean" % name, mean)
    stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
    tf.summary.scalar("%s_stddev" % name, stddev)
    tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))


def _mask(x, batch_axis, axis, pos, max_amount):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int batch_axis:
    :param int axis:
    :param tf.Tensor pos: (batch,)
    :param int|tf.Tensor max_amount: inclusive
    """
    import tensorflow as tf
    ndim = x.get_shape().ndims
    n_batch = tf.shape(x)[batch_axis]
    dim = tf.shape(x)[axis]
    amount = tf.random_uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
    pos2 = tf.minimum(pos + amount, dim)
    idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
    pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
    pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
    cond = tf.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
    if batch_axis > axis:
        cond = tf.transpose(cond)  # (dim,batch)
    cond = tf.reshape(cond, [tf.shape(x)[i] if i in (batch_axis, axis) else 1 for i in range(ndim)])
    from TFUtil import where_bc
    x = where_bc(cond, 0.0, x)
    return x


def random_mask(x, batch_axis, axis, min_num, max_num, max_dims):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int batch_axis:
    :param int axis:
    :param int|tf.Tensor min_num:
    :param int|tf.Tensor max_num: inclusive
    :param int|tf.Tensor max_dims: inclusive
    """
    import tensorflow as tf
    n_batch = tf.shape(x)[batch_axis]
    if isinstance(min_num, int) and isinstance(max_num, int) and min_num == max_num:
        num = min_num
    else:
        num = tf.random_uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
    # https://github.com/tensorflow/tensorflow/issues/9260
    # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
    z = -tf.log(-tf.log(tf.random_uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
    _, indices = tf.nn.top_k(z, num if isinstance(num, int) else tf.reduce_max(num))
    # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
    # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
    if isinstance(num, int):
        for i in range(num):
            x = _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims)
    else:
        _, x = tf.while_loop(
            cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
            body=lambda i, x: (
                i + 1,
                tf.where(
                    tf.less(i, num),
                    _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims),
                    x)),
            loop_vars=(0, x))
    return x


def transform(data, network, time_factor=1):
    x = data.placeholder
    import tensorflow as tf
    # summary("features", x)
    step = network.global_train_step
    step1 = tf.where(tf.greater_equal(step, 1000), 1, 0)
    step2 = tf.where(tf.greater_equal(step, 2000), 1, 0)
    def get_masked():
        x_masked = x
        x_masked = random_mask(
          x_masked, batch_axis=data.batch_dim_axis, axis=data.time_dim_axis,
          min_num=step1 + step2, max_num=tf.maximum(tf.shape(x)[data.time_dim_axis] // 100, 2) * (1 + step1 + step2 * 2),
          max_dims=20 // time_factor)
        x_masked = random_mask(
          x_masked, batch_axis=data.batch_dim_axis, axis=data.feature_dim_axis,
          min_num=step1 + step2, max_num=2 + step1 + step2 * 2,
          max_dims=data.dim // 5)
        #summary("features_mask", x_masked)
        return x_masked
    x = network.cond_on_train(get_masked, lambda: x)
    return x


def t_linear(source, **kwargs):
    import tensorflow as tf
    from TFUtil import where_bc
    enc = source(1, as_data=True, auto_convert=False)
    dec = source(0, as_data=True, auto_convert=False)
    enc_lens = enc.get_sequence_lengths()
    dec_lens = dec.get_sequence_lengths()
    dec_shape = tf.shape(dec.placeholder)
    batch_dim = dec_shape[dec.batch_dim_axis]
    dec_time_dim = dec_shape[dec.time_dim_axis]
    dec_times = tf.expand_dims(tf.range(dec_time_dim), axis=0)  # (1,dec-T)
    x = tf.cast(dec_times + 1, tf.float32)  # (1,dec-T)
    # We want: x[dec_len - 1] == enc_time - 1.
    factors = tf.maximum(tf.cast(enc_lens - 1, tf.float32), 0.0) / tf.maximum(tf.cast(dec_lens, tf.float32), 1.0)  # (B,)
    # The definition does not allow loops, thus this is the minimum factor.
    factors = tf.maximum(factors, 1.0)
    factors = tf.expand_dims(factors, axis=1)  # (B,1)
    x = x * factors  # (B,dec-T)
    x = tf.cast(tf.round(x), tf.int32)
    # Note: If this causes loops in the very last frame, this is ok currently.
    x = tf.minimum(x, tf.expand_dims(enc_lens - 1, axis=1))
    # fix cheating gold targets with end flag filter. must be 0
    x = where_bc(tf.less(dec_times, tf.expand_dims(dec_lens, axis=1)), x, 0)
    return x

def t_search_t_loop_err(source, **kwargs):
    import tensorflow as tf
    from TFUtil import where_bc
    ts_search = source(0, as_data=True, auto_convert=False).copy_as_batch_major()  # (B,T)
    seq_lens = ts_search.get_sequence_lengths()  # (B,)
    seq_lens_bc = seq_lens[:, None]  # (B,1)
    l = tf.equal(ts_search.placeholder[:,1:], ts_search.placeholder[:,:-1])  # (B,T-1)
    l = tf.cast(l, tf.int32)  # 1 if err else 0
    l = tf.pad(l, [[0,0],[1,0]])  # (B,T)
    l = where_bc(tf.less(tf.range(tf.shape(l)[1])[None,:], seq_lens_bc), l, 0)
    l = tf.reduce_sum(l, axis=1)  # (B,)
    l = tf.cast(l, tf.float32) / tf.cast(seq_lens, tf.float32)  # (B,)
    return l

def t_search_or_fallback(source, **kwargs):
    import tensorflow as tf
    from TFUtil import where_bc
    ts_linear = source(0)  # (B,T)
    ts_search = source(1)  # (B,T)
    l = source(2, auto_convert=False)  # (B,)
    return where_bc(tf.less(l[:, None], 0.01), ts_search, ts_linear)


StoreAlignmentUpToEpoch = 30 * EpochSplit  # 0 based, exclusive
AlignmentFilenamePattern = "net-model/alignments.%i.hdf"

def get_most_recent_align_hdf_files(epoch0):
    """
    :param int epoch0: 0-based (sub) epoch
    :return: filenames or None if there is nothing completed yet
    :rtype: list[str]|None
    """
    if epoch0 < EpochSplit:
        return None
    if epoch0 > StoreAlignmentUpToEpoch:
        epoch0 = StoreAlignmentUpToEpoch  # first epoch after
    i = ((epoch0 - EpochSplit) // EpochSplit) * EpochSplit
    return [AlignmentFilenamePattern % j for j in range(i, i + EpochSplit)]


def t_recomb_train(layer, batch_dim, scores_in, scores_base, base_beam_in, end_flags, **kwargs):
    """
    :param ChoiceLayer layer:
    :param tf.Tensor batch_dim: scalar
    :param tf.Tensor scores_base: (batch,base_beam_in,1). existing beam scores
    :param tf.Tensor scores_in: (batch,base_beam_in,dim). log prob frame distribution
    :param tf.Tensor end_flags: (batch,base_beam_in)
    :param int base_beam_in:
    :rtype: tf.Tensor
    :return: (batch,base_beam_in,dim), combined scores
    """
    import tensorflow as tf
    from TFUtil import where_bc
    end_flags = tf.expand_dims(end_flags, axis=-1)  # (batch,beam,1)
    scores = scores_in + scores_base  # (batch,beam,dim)
    best_idxs = tf.cast(tf.argmax(scores, axis=1), tf.int32)  # (batch,dim) -> beam idx
    mask = tf.equal(tf.range(base_beam_in)[None,:,None], best_idxs[:,None,:])  # (batch,beam,dim)
    mask2 = tf.equal(tf.range(base_beam_in)[None,:,None], base_beam_in - 1)  # keep last beam as-is for cheating
    mask = tf.logical_or(mask, mask2) 
    recomb_scores = where_bc(mask, scores, float("-inf"))
    return where_bc(end_flags, scores, recomb_scores)


def search_checks(layer):
    """
    :param ChoiceLayer layer:
    :rtype: list[tf.Operation]
    """
    if task != "train":
        return []
    if not layer.search_choices:  # training without search
        return []
    import tensorflow as tf
    from TFUtil import get_shape
    from TFNetworkLayer import SelectSearchSourcesLayer
    checks = []
    # Make sure: In each batch entry, there is at least one beam with non-inf score.
    beam_scores = layer.search_choices.beam_scores  # (batch,beam)
    i = layer.network.get_rec_step_index()
    n_batch, n_beam = get_shape(beam_scores)
    label = tf.reshape(layer.output.placeholder, (n_batch, n_beam))  # (batch,beam)
    in_scores = tf.reshape(SelectSearchSourcesLayer.select_if_needed(
        layer.sources[0], search_choices=layer.search_choices).output.placeholder,
        (n_batch, n_beam, -1))  # (batch,beam,dim)
    if layer.name == "t0":
        t_layer = layer
    else:
        t_layer = SelectSearchSourcesLayer.select_if_needed(
            layer=layer.network.get_layer("t"),
            search_choices=layer.search_choices)
    t = tf.reshape(t_layer.output.placeholder, (n_batch, n_beam))  # (batch,beam)
    prev_t_layer = SelectSearchSourcesLayer.select_if_needed(
        layer=layer.network.get_layer("prev:t"),
        search_choices=layer.search_choices)
    prev_t = tf.reshape(prev_t_layer.output.placeholder, (n_batch, n_beam))  # (batch,beam)
    t_base_seq = layer.network.get_layer("base:data:t_base").output.placeholder  # (batch,dec-T)
    t_base = layer.network.get_layer("data:t_base").output.placeholder  # (batch,)
    enc_seq_lens = layer.network.get_layer("base:encoder").output.get_sequence_lengths()  # (batch,)  
    dec_seq_lens = layer.network.get_layer("base:data:%s" % target).output.get_sequence_lengths()  # (batch,)
    end_flags = tf.reshape(layer.network.get_rec_step_info().get_end_flag(
        target_search_choices=layer.search_choices), (n_batch, n_beam))  # (batch,beam)
    beam_scores_finite = tf.is_finite(beam_scores)
    beam_scores_any_finite = tf.reduce_any(beam_scores_finite, axis=1)  # (batch,)
    beam_scores_cheat_finite = beam_scores_finite[:,-1]  # (batch,). the last beam is the cheating beam
    t_check = tf.logical_or(end_flags, tf.greater(t, prev_t))  # (batch,beam)
    t_check = tf.logical_or(t_check, tf.equal(t, enc_seq_lens[:,None] - 1))  # allow to loop in last frame
    t_check = tf.logical_and(tf.reduce_any(t_check, axis=1), t_check[:,-1])  # (batch,)
    bad_batch_idx = tf.argmin(tf.cast(
        tf.logical_and(tf.logical_and(beam_scores_any_finite, beam_scores_cheat_finite), t_check), tf.int32))
    checks.append(
        tf.Assert(
            tf.logical_and(
                tf.logical_and(tf.reduce_all(beam_scores_any_finite), tf.reduce_all(beam_scores_cheat_finite)),
                tf.reduce_all(t_check)),
            ["layer", layer.name, "i", i,
             "any_finite", beam_scores_any_finite, "cheat_finite", beam_scores_cheat_finite,
             "bad_batch_idx", bad_batch_idx, "n_batch", n_batch, "n_beam", n_beam,
             "beam scores", beam_scores[bad_batch_idx],
             "label", label[bad_batch_idx],
             "t", t[bad_batch_idx], "prev:t", prev_t[bad_batch_idx],
             "t_base", t_base[bad_batch_idx], "t_base seq", t_base_seq[bad_batch_idx],
             "enc_seq_len", enc_seq_lens[bad_batch_idx],
             "dec_seq_len", dec_seq_lens[bad_batch_idx],
             "end_flag", end_flags[bad_batch_idx],
             "scores_in_", in_scores[bad_batch_idx], in_scores[bad_batch_idx,-1],
             "scores_in", layer.search_scores_in[bad_batch_idx, -1],
             "scores_base", layer.search_scores_base[bad_batch_idx],
             "scores_comb", layer.search_scores_combined[bad_batch_idx, -1]],
            summarize=100,
            name="beam_scores_finite_check"))
    return checks

# InvalidArgumentError (see above for traceback): assertion failed: [beam scores] [[nan nan nan nan nan nan nan -inf]] [i] [3] [t] [[0 1 2 3 4 5 6 11]] [prev:t] [[17 17 17 17 17 17 17 8]] [t_base] [11] [t_base seq] [[3 6 8 11 14 17]] [enc_seq_lens] [18]
# InvalidArgumentError (see above for traceback): assertion failed: [layer] [output] [i] [1] [any_finite] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...] [cheat_finite] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...] [bad_batch_idx] [0] [beam scores] [nan] [t] [0] [prev:t] [10] [t_base] [19] [t_base seq] [10 19 0 0 0 0 0 0 0 0] [enc_seq_len] [20] [scores_in_] [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]...] [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan...] [scores_in] [nan] [scores_base] [-12.133996] [scores_comb] [nan]
# Invalid argument: assertion failed: [layer] [t0] [i] [3] [any_finite] [1 1 1 1 0 1 1 1 1 1 1 1 1] [cheat_finite] [1 1 1 1 0 1 1 1 1 1 1 1 1] [bad_batch_idx] [4] [n_batch] [13] [n_beam] [1] [beam scores] [-inf] [label] [2] [t] [2] [prev:t] [2] [t_base] [2] [t_base seq] [0 1 2 2 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [enc_seq_len] [4] [dec_seq_len] [6] [end_flag] [0] [scores_in_] [[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]...] [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...] [scores_in] [-inf -inf -inf 0 -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf...] [scores_base] [[-24.8847466]] [scores_comb] [-inf -inf -inf -24.8847466 -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf...]


def get_net_dict(pretrain_idx):
    """
    :param int|None pretrain_idx: starts at 0. note that this has a default repetition factor of 6
    :return: net_dict or None if pretrain should stop
    :rtype: dict[str,dict[str]|int]|None
    """
    # Note: epoch0 is 0-based here! I.e. in contrast to elsewhere, where it is 1-based.
    # Also, we never use #repetition here, such that this is correct.
    # This is important because of sub-epochs and storing the HDF files,
    # to know exactly which HDF files cover the dataset completely.
    epoch0 = pretrain_idx
    net_dict = {}

    have_existing_align = False  # only in training, and only in pretrain, and only after the first epoch
    if pretrain_idx is not None:
        net_dict["#config"] = {}

        if task == "train":
            most_recent_align_hdf_files = get_most_recent_align_hdf_files(epoch0)
            have_existing_align = bool(most_recent_align_hdf_files)

            net_dict["#config"].update({
                "train": get_sprint_dataset("train", hdf_files=most_recent_align_hdf_files),
                "dev": get_sprint_dataset("cv", hdf_files=most_recent_align_hdf_files),
            })

        # Do this in the very beginning.
        lr_warmup = list(numpy.linspace(0.0001, learning_rate, num=10))
        lr_warmup += [learning_rate] * 10
        if pretrain_idx < len(lr_warmup):
            net_dict["#config"]["learning_rate"] = lr_warmup[pretrain_idx]
        pretrain_idx -= len(lr_warmup)

        #if pretrain_idx < 0 and task == "train":
        #    net_dict["#config"]["batch_size"] = 20000

    use_t_search_as_target = not have_existing_align or epoch0 < StoreAlignmentUpToEpoch
    use_t_start_zero = False  #pretrain_idx is not None and pretrain_idx <= 2

    if pretrain_idx is not None:
        # First with soft att, later without. Repeat a bit.
        pretrain_idx -= 5

    start_num_lstm_layers = 6
    final_num_lstm_layers = 6
    num_lstm_layers = final_num_lstm_layers
    if pretrain_idx is not None:
        pretrain_idx = max(pretrain_idx, 0) // 5  # Repeat a bit.
        num_lstm_layers = pretrain_idx + start_num_lstm_layers
        pretrain_idx = num_lstm_layers - final_num_lstm_layers
        num_lstm_layers = min(num_lstm_layers, final_num_lstm_layers)

    start_dim_factor = 0.5
    grow_frac = 1.0 # - float(final_num_lstm_layers - num_lstm_layers) / (final_num_lstm_layers - start_num_lstm_layers)
    dim_frac = start_dim_factor + (1.0 - start_dim_factor) * grow_frac

    time_reduction = [3, 2] if num_lstm_layers >= 3 else [6]

    if pretrain_idx is not None and pretrain_idx <= 1 and "learning_rate" not in net_dict["#config"]:
        # Fixed learning rate for the beginning.
        net_dict["#config"]["learning_rate"] = learning_rate

    if pretrain_idx is not None and use_t_search_as_target and "batch_size" not in net_dict["#config"] and task == "train":
        # With search, and not the smallest encoder, it consumes more memory.
        net_dict["#config"]["batch_size"] = 10000

    net_dict["#info"] = {
        "epoch0": epoch0,  # Set this here such that a new construction for every pretrain idx is enforced in all cases.
        "num_lstm_layers": num_lstm_layers,
        "dim_frac": dim_frac,
        "have_existing_align": have_existing_align,
        "use_t_search_as_target": use_t_search_as_target,
        "use_t_start_zero": use_t_start_zero,
    }

    # We use this pretrain construction during the whole training time (epoch0 > num_epochs).
    if pretrain_idx is not None and epoch0 % EpochSplit == 0 and epoch0 > num_epochs:
        # Stop pretraining now.
        return None

    net_dict.update({
        "source": {"class": "eval", "eval": "self.network.get_config().typed_value('transform')(source(0, as_data=True), network=self.network)"},
        "source0": {"class": "split_dims", "axis": "F", "dims": (-1, 1), "from": "source"},  # (T,40,1)

        # Lingvo: ep.conv_filter_shapes = [(3, 3, 1, 32), (3, 3, 32, 32)],  ep.conv_filter_strides = [(2, 2), (2, 2)]
        "conv0": {"class": "conv", "from": "source0", "padding": "same", "filter_size": (3, 3), "n_out": 32, "activation": None, "with_bias": True},  # (T,40,32)
        "conv0p": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (1, 2), "from": "conv0"},  # (T,20,32)
        "conv1": {"class": "conv", "from": "conv0p", "padding": "same", "filter_size": (3, 3), "n_out": 32, "activation": None, "with_bias": True},  # (T,20,32)
        "conv1p": {"class": "pool", "mode": "max", "padding": "same", "pool_size": (1, 2), "from": "conv1"},  # (T,10,32)
        "conv_merged": {"class": "merge_dims", "from": "conv1p", "axes": "static"},  # (T,320)
        "conv_merged1": {"class": "postfix_in_time", "postfix": 0.0, "repeat": 10, "from": "conv_merged"},

        # Encoder LSTMs added below, resulting in "encoder0".

        "encoder": {"class": "copy", "from": "encoder0"},

        "enc_ctx": {"class": "linear", "activation": None, "with_bias": True, "from": ["encoder"], "n_out": EncKeyTotalDim},
        "enc_value": {"class": "copy", "from": "encoder"},  # (B, enc-T, D)
        "enc_seq_len": {"class": "length", "from": "encoder", "sparse": True},

        # for task "search" / search_output_layer
        "decision": {
            "class": "decide", "from": "output", "loss": "edit_distance", "target": target,
            'only_on_search': True},

        "t_linear": {
            "class": "eval", "from": ["data:%s" % target, "encoder"], "eval": t_linear,
            "out_type": {"batch_dim_axis": 0, "time_dim_axis": 1, "shape": (None,), "sparse": True, "dtype": "int32", "dim": None},
            "size_target": target},

        # Target for decoder ('output') with search ("extra.search") in training.
        # The layer name must be smaller than "t_target" such that this is created first.
        "1_t_base": {
            "class": "copy",
            "from": "existing_alignment" if have_existing_align else "t_linear",
            "register_as_extern_data": "t_base"},

        "2_t_target": {
            "class": "copy",
            "from": "extra.search:t_search_or_fallback" if use_t_search_as_target else "data:t_base",
            "register_as_extern_data": "t_target" if task == "train" else None},

        #"ctc": {"class": "softmax", "from": "encoder", "loss": "ctc", "target": target,
        #    "loss_opts": {"beam_width": 1, "use_native": True}},
    })

    if have_existing_align:
        net_dict.update({
            # This should be compatible to t_linear or t_search.
            "existing_alignment": {
                "class": "reinterpret_data", "from": "data:alignment",
                "set_sparse": True,  # not sure what the HDF gives us
                "set_sparse_dim": None,
                "size_base": "data:%s" % target,
                },
            # This should be compatible to search_score.
            "existing_align_score": {
                "class": "squeeze", "from": "data:align_score", "axis": "f",
                "loss": "as_is", "loss_scale": 0
                }
            })

    # Add encoder BLSTM stack.
    src = "conv_merged1"
    if num_lstm_layers >= 1:
        net_dict.update({
            "lstm0_fw": {"class": "rec", "unit": "nativelstm2", "n_out": int(LstmDim * dim_frac), "direction": 1, "from": src},
            "lstm0_bw": {"class": "rec", "unit": "nativelstm2", "n_out": int(LstmDim * dim_frac), "direction": -1, "from": src}})
        src = ["lstm0_fw", "lstm0_bw"]
    for i in range(1, num_lstm_layers):
        red = time_reduction[i - 1] if (i - 1) < len(time_reduction) else 1
        net_dict.update({
            "lstm%i_pool" % (i - 1): {"class": "pool", "mode": "max", "padding": "same", "pool_size": (red,), "from": src}})
        src = "lstm%i_pool" % (i - 1)
        net_dict.update({
            "lstm%i_fw" % i: {"class": "rec", "unit": "nativelstm2", "n_out": int(LstmDim * dim_frac), "direction": 1, "from": src, "dropout": 0.3 * dim_frac},
            "lstm%i_bw" % i: {"class": "rec", "unit": "nativelstm2", "n_out": int(LstmDim * dim_frac), "direction": -1, "from": src, "dropout": 0.3 * dim_frac}})
        src = ["lstm%i_fw" % i, "lstm%i_bw" % i]
    net_dict["encoder0"] = {"class": "copy", "from": src}  # dim: EncValueTotalDim

    def get_output_dict(train, search, t_target, beam_size=beam_size):
        return {"class": "rec", "from": [], "back_prop": (task == "train") and train,
        "unit": {
            "s_transformed": {"class": "linear", "activation": None, "with_bias": False, "from": ["s"], "n_out": EncKeyTotalDim},
            "energy_in": {"class": "combine", "kind": "add", "from": ["base:enc_ctx", "s_transformed"], "n_out": EncKeyTotalDim},
            "energy_tanh": {"class": "activation", "activation": "tanh", "from": "energy_in"},

            "energy": {"class": "linear", "activation": None, "with_bias": False, "from": ["energy_tanh"], "n_out": AttNumHeads},  # (B, enc-T, H)
            "energy1": {"class": "squeeze", "axis": "f", "from": "energy"},  # (B, enc-T)
            "energy2": {"class": "reinterpret_data", "from": "energy1", "set_axes": {"t": "stag:lstm"}},

            # Segment boundaries:
            # - t0/t1/t is the right side (inclusive)
            # - prev:t is the left side (exclusive)
            # - t_start/prev_t_plus1 is the left side (inclusive)

            "prev_t_plus1": {"class": "eval", "from": "prev:t", "eval": "source(0) + 1"},
            "t_start": {
                "class": "eval", "from": ["prev_t_plus1", "base:enc_seq_len"],
                "eval": "tf.minimum(source(0), source(1) - 1)"},  # to avoid nans

            "t_weights": {
                "class": "softmax_over_spatial", "from": "energy2", "axis": "stag:lstm",
                "start": "t_start"},
            "t_weights1": {
                # ChoiceLayer works on the feature axis.
                "class": "reinterpret_data", "from": "t_weights", "set_axes": {"f": "stag:lstm"},
                # Loss for weights.
                "target": t_target if train else None,
                "loss": "ce" if (train and t_target) else None,
                "loss_opts": {
                  #"label_smoothing": 0.1 if pretrain_idx is None or pretrain_idx >= 1 else 0.0,
                  "scale": 0.1}
                  if (train and t_target) else None,
            },

            "t0": {
                "class": "choice", "from": "t_weights1",
                "target": t_target, "cheating": bool(t_target),  # add this in training
                "beam_size": beam_size * 4 if task == "search" else beam_size,
                "keep_beams": task == "search",
                "custom_score_combine": t_recomb_train if (search and t_target) else None,
                "control_dependencies_on_output": search_checks,
                "length_normalization": False, "initial_output": -1},  # (B,)
            # Note: If beam-size > enc_seq_len, we end up with invalid t in the beam. Fix that.
            "t1": {
                "class": "eval", "from": ["t0", "t_start", "base:enc_seq_len"],
                "eval": "tf.clip_by_value(source(0), source(1), source(2) - 1)"},
            "t": {
                #"class": "print",
                "class": "copy",
                "from": "t1", "initial_output": -1, "is_output_layer": bool(search)},
            "window_start": {"class": "eval", "from": "t", "eval": "source(0) - 5"},

            "att_weights": {
                "class": "softmax_over_spatial", "from": "energy2", "axis": "stag:lstm",
                "window_start": "window_start",
                "window_size": 10},  # (B, enc-T)
            "att_soft": {"class": "generic_attention", "weights": "att_weights", "base": "base:enc_value"},  # (B, V)
            "att": {"class": "copy", "from": "att_soft"},
            
            "s": {"class": "rec", "unit": "nativelstm2", "from": ["prev:target_embed", "prev:att"], "n_out": 1000},
            "readout_in": {"class": "linear", "from": ["s", "prev:target_embed", "att"], "activation": None, "n_out": 1000},
            "readout": {"class": "reduce_out", "mode": "max", "num_pieces": 2, "from": ["readout_in"]},
            "output_prob": {"class": "softmax", "from": ["readout"], "dropout": 0.3, "target": target,
                "loss": "ce" if train else None,
                "loss_opts": {"label_smoothing": 0.1 if pretrain_idx is None or pretrain_idx >= 1 else 0.0}
                             if train else None},

            'target_embed': {'class': 'linear', 'activation': None, "with_bias": False, 'from': ['output'], "n_out": 621, "initial_output": "var"},
            'output': {
                'class': 'choice', 'target': target, 'beam_size': beam_size, 'from': ["output_prob"], "initial_output": 0,
                "control_dependencies_on_output": search_checks,
                'search': task != 'train', "length_normalization": task != "train"},

            #"end": {"class": "compare", "from": ["t", "base:enc_seq_len"], "kind": "greater"},
            "end": {"class": "compare", "from": "output", "value": 0},

            },
            "target": [target, t_target] if t_target else [target],
            "size_target": t_target,
            "max_seq_len": "max_len_from('base:encoder0')"}

    if task == "train":
        if use_t_search_as_target:
            net_dict.update({
                "extra.search:output":
                    get_output_dict(
                        train=False, search=True, t_target="t_base",
                        # In case we don't have an existing alignment, use the linear alignment (t_base),
                        # and don't do any further search (we use cheating), to just measure the search score.
                        beam_size=beam_size if (have_existing_align or debug_mode) else 1
                        ),
                "extra.search:t_search": {"class": "decide", "from": "extra.search:output/t"},
                "extra.search:search_loss": {
                    "class": "decide", "from": "extra.search:output", "loss": "search_score", "loss_scale": 0},
                "extra.search:search_score": {
                    "class": "eval", "from": "extra.search:search_loss",
                    "out_type": {"dtype": "float32", "sparse": False, "shape": (), "dim": None, "batch_dim_axis": 0, "time_dim_axis": None},
                    "eval": "(source(0, auto_convert=False), tf.squeeze(self.sources[0].search_choices.beam_scores, axis=1) / tf.cast(source(0, auto_convert=False, as_data=True).get_sequence_lengths(), tf.float32))[-1]",
                    "loss": "as_is", "loss_scale": 0},
                "t_search_t_loop_err": {
                    "class": "eval", "from": "extra.search:t_search",
                    "eval": t_search_t_loop_err,
                    "out_type": {"batch_dim_axis": 0, "time_dim_axis": None, "shape": (), "dim": None, "dtype": "float32"},
                    "loss": "as_is", "loss_scale": 0},
                "t_search_linear_err": {
                    "class": "eval", "from": ["extra.search:t_search", "t_linear"],
                    "eval": "tf.cast(tf.abs(source(0) - source(1)), tf.float32)",
                    "out_type": {"dtype": "float32", "sparse": False, "dim": None},
                    "loss": "as_is", "loss_scale": 0},
                "use_t_search":
                    {"class": "compare", "kind": "less", "from": ["existing_align_score", "extra.search:search_score"]}
                    if have_existing_align else
                    {"class": "constant", "value": True},
                "t_search_or_fallback": {
                    "class": "switch", "condition": "use_t_search",
                    "true_from": "extra.search:t_search", "false_from": "data:t_base"}
                    if have_existing_align else
                    {"class": "copy", "from": "data:t_base"},
                "t_search_or_fallback_score":
                    {"class": "switch", "condition": "use_t_search",
                     "true_from": "extra.search:search_score", "false_from": "existing_align_score"}
                    if have_existing_align else
                    {"class": "copy", "from": "extra.search:search_score"},
            })
            if epoch0 is not None and epoch0 < StoreAlignmentUpToEpoch:
                net_dict.update({
                    "extra.search:t_search_dump": {
                        "class": "hdf_dump", "from": "t_search_or_fallback",
                        "extra": {"scores": "t_search_or_fallback_score"},
                        "filename": AlignmentFilenamePattern % epoch0,
                        "is_output_layer": True},
                    })

            net_dict["extra.search:output"]["unit"].update({
              "t_base_err": {
                "class": "eval", "from": ["t", "data:t_base"], "collocate_with": "t",
                "eval": "tf.cast(tf.abs(source(0) - source(1)), tf.float32)",
                "loss": "as_is",
                "loss_scale": 0,
                "out_type": {"dtype": "float32"}},
              "t_loop_err": {
                "class": "eval", "from": ["t", "prev:t"], "collocate_with": "t",
                "eval": "where_bc(tf.equal(source(0), source(1)), 1., 0.)",
                "loss": "as_is",
                "loss_scale": 0,
                "out_type": {"dtype": "float32"}}})

        net_dict["output"] = get_output_dict(train=True, search=False, t_target="t_target")
    else:
        net_dict["output"] = get_output_dict(train=True, search=True, t_target=None)

    return net_dict


network = get_net_dict(pretrain_idx=None)
search_output_layer = "decision"
debug_print_layer_output_template = True

# trainer
batching = "random"
# Seq-length 'data' Stats:
#  37867 seqs
#  Mean: 447.397258827
#  Std dev: 350.353162012
#  Min/max: 15 / 2103
# Seq-length 'bpe' Stats:
#  37867 seqs
#  Mean: 14.1077719386
#  Std dev: 13.3402518828
#  Min/max: 2 / 82
log_batch_size = True
batch_size = 10000
max_seqs = 200
if debug_mode:
    max_seqs = 1
max_seq_length = {"bpe": 75}
#chunking = ""  # no chunking
truncation = -1

def custom_construction_algo(idx, net_dict):
    # For debugging, use: python3 ./crnn/Pretrain.py config...
    return get_net_dict(pretrain_idx=idx)

# No repetitions here. We explicitly do that in the construction.
pretrain = {"copy_param_mode": "subset", "construction_algo": custom_construction_algo}

preload_from_files = {
  "base": {
    "init_for_train": True,
    "ignore_missing": True,
    "filename": "base/data-train/base2.conv2l.specaug4a/net-model/network.160",
  }
}

num_epochs = 100
model = "net-model/network"
cleanup_old_models = True
gradient_clip = 0
#gradient_clip_global_norm = 1.0
adam = True
optimizer_epsilon = 1e-8
accum_grad_multiple_step = 2
#debug_add_check_numerics_ops = True
#debug_add_check_numerics_on_output = True
tf_log_memory_usage = True
gradient_noise = 0.0
# lr set above
learning_rate_control = "newbob_multi_epoch"
learning_rate_control_error_measure = "dev_error_output/output_prob"
learning_rate_control_relative_error_relative_lr = True
learning_rate_control_min_num_epochs_per_new_lr = 3
use_learning_rate_control_always = True
newbob_multi_num_epochs = 6
newbob_multi_update_interval = 1
newbob_learning_rate_decay = 0.7
learning_rate_file = "newbob.data"

# log
#log = "| /u/zeyer/dotfiles/system-tools/bin/mt-cat.py >> log/crnn.seq-train.%s.log" % task
log = "log/crnn.%s.log" % task
log_verbosity = 5



